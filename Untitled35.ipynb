{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8bea812c-4b8a-4538-ad42-3a9897b2b86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9035087719298246\n",
      "\n",
      "Confusion Matrix:\n",
      "[[63  5]\n",
      " [ 6 40]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92        68\n",
      "           1       0.89      0.87      0.88        46\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.90      0.90      0.90       114\n",
      "weighted avg       0.90      0.90      0.90       114\n",
      "\n",
      "\n",
      "Enter values for prediction:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "nWBV (numeric):  .75\n",
      "MMSE (numeric):  28\n",
      "M/F (1=Male,0=Female):  0\n",
      "eTIV (numeric):  1200\n",
      "SES (numeric):  1\n",
      "Age (numeric):  55\n",
      "ASF (numeric):  .6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction: Alzheimers Unlikely\n",
      "Probability of Alzheimer's: 0.38\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# === Load datasets ===\n",
    "cross_df = pd.read_csv(\"oasis_cross-sectional.csv\")\n",
    "long_df = pd.read_csv(\"oasis_longitudinal.csv\")\n",
    "\n",
    "# === Preprocess cross-sectional ===\n",
    "cross_df = cross_df.drop(columns=['ID', 'Hand', 'Delay'], errors='ignore')\n",
    "cross_df = cross_df.dropna(subset=['CDR', 'MMSE', 'Educ'])\n",
    "cross_df['M/F'] = cross_df['M/F'].map({'M': 1, 'F': 0})\n",
    "cross_df['Alzheimers'] = cross_df['CDR'].apply(lambda x: 1 if x >= 0.5 else 0)\n",
    "cross_df = cross_df.drop(columns=['CDR'], errors='ignore')\n",
    "\n",
    "# === Preprocess longitudinal ===\n",
    "long_df = long_df.drop(columns=['Subject ID', 'MRI ID', 'Group', 'Visit', 'MR Delay', 'Hand', 'Delay'], errors='ignore')\n",
    "long_df = long_df.dropna(subset=['CDR', 'MMSE', 'EDUC'])\n",
    "long_df['M/F'] = long_df['M/F'].map({'M': 1, 'F': 0})\n",
    "long_df['Alzheimers'] = long_df['CDR'].apply(lambda x: 1 if x >= 0.5 else 0)\n",
    "long_df = long_df.drop(columns=['CDR'], errors='ignore')\n",
    "\n",
    "# === Select features common to both datasets ===\n",
    "features = ['Age', 'Educ', 'MMSE', 'eTIV', 'nWBV', 'ASF', 'M/F', 'SES', 'Alzheimers']\n",
    "common_features = list(set(features).intersection(set(cross_df.columns)).intersection(set(long_df.columns)))\n",
    "\n",
    "cross_df_filtered = cross_df[common_features]\n",
    "long_df_filtered = long_df[common_features]\n",
    "\n",
    "combined_df = pd.concat([cross_df_filtered, long_df_filtered], ignore_index=True).dropna()\n",
    "\n",
    "X = combined_df.drop(columns=['Alzheimers'])\n",
    "y = combined_df['Alzheimers']\n",
    "\n",
    "# === Train-test split ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# === Scale features ===\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# === Train stacking classifier ===\n",
    "lr_model = LogisticRegression(max_iter=1000, class_weight='balanced', solver='liblinear',C=0.1)\n",
    "rf_model = RandomForestClassifier(n_estimators=200,max_depth=10,min_samples_split=4,random_state=42, class_weight='balanced')\n",
    "\n",
    "stack = StackingClassifier(\n",
    "    estimators=[('lr', lr_model), ('rf', rf_model)],\n",
    "    final_estimator=LogisticRegression(class_weight='balanced', solver='liblinear'),\n",
    "    cv=5\n",
    ")\n",
    "stack.fit(X_train_scaled, y_train)\n",
    "\n",
    "# === Evaluate ===\n",
    "y_pred = stack.predict(X_test_scaled)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# === User input for prediction ===\n",
    "print(\"\\nEnter values for prediction:\")\n",
    "\n",
    "input_data = {}\n",
    "for feature in X.columns:\n",
    "    while True:\n",
    "        try:\n",
    "            val = input(f\"{feature} ({'1=Male,0=Female' if feature == 'M/F' else 'numeric'}): \")\n",
    "            if feature == 'M/F':\n",
    "                val = int(val)\n",
    "                if val not in [0, 1]:\n",
    "                    print(\"Enter 1 for Male or 0 for Female.\")\n",
    "                    continue\n",
    "            else:\n",
    "                val = float(val)\n",
    "            input_data[feature] = val\n",
    "            break\n",
    "        except ValueError:\n",
    "            print(\"Invalid input, please enter a valid number.\")\n",
    "\n",
    "input_df = pd.DataFrame([input_data])\n",
    "input_scaled = scaler.transform(input_df)\n",
    "\n",
    "pred = stack.predict(input_scaled)[0]\n",
    "prob = stack.predict_proba(input_scaled)[0][1]\n",
    "\n",
    "print(f\"\\nPrediction: {'Alzheimers Likely' if pred == 1 else 'Alzheimers Unlikely'}\")\n",
    "print(\n",
    "\n",
    "f\"Probability of Alzheimer's: {prob:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d38209-f170-4cdf-a83c-83dcb60d12e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
